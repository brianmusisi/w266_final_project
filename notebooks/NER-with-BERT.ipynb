{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0803 21:34:51.661870 139944051242816 deprecation_wrapper.py:119] From /home/brianmusisi/anaconda3/lib/python3.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data with entities replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>class</th>\n",
       "      <th>modified_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tibit Communications Raises $20M in Series B F...</td>\n",
       "      <td>Tibit Communications, Inc., a Petaluma, CA-bas...</td>\n",
       "      <td>http://www.finsmes.com/2019/04/tibit-communica...</td>\n",
       "      <td>FinsmesUSA</td>\n",
       "      <td>Funding</td>\n",
       "      <td>organization, a Petaluma, organization-based s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Twitter blames human error after blocking a Ne...</td>\n",
       "      <td>Over the holiday weekend, The New York Times f...</td>\n",
       "      <td>https://techcrunch.com/2017/11/27/twitter-blam...</td>\n",
       "      <td>techcrunch</td>\n",
       "      <td>Other</td>\n",
       "      <td>Over the holiday weekend, organization found t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SimplyCook Raises £4.5M in Series A Funding\\n</td>\n",
       "      <td>SimplyCook, a London, UK-based recipe kit serv...</td>\n",
       "      <td>http://www.finsmes.com/2019/01/simplycook-rais...</td>\n",
       "      <td>FinsmesUK</td>\n",
       "      <td>Funding</td>\n",
       "      <td>organization, a London, UK-based recipe kit se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Moogsoft Secures $40M in Series D Funding\\n</td>\n",
       "      <td>Moogsoft, a San Francisco, CA-based provider o...</td>\n",
       "      <td>http://www.finsmes.com/2018/03/moogsoft-secure...</td>\n",
       "      <td>FinsmesUSA</td>\n",
       "      <td>Funding</td>\n",
       "      <td>organization, a San Francisco, organization-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Zeta Global acquires commenting service†Disqus</td>\n",
       "      <td>A source close to the two companies tells us t...</td>\n",
       "      <td>https://techcrunch.com/2017/12/05/zeta-global-...</td>\n",
       "      <td>techcrunch</td>\n",
       "      <td>Other</td>\n",
       "      <td>A source close to the two companies tells us t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Tibit Communications Raises $20M in Series B F...   \n",
       "1           1  Twitter blames human error after blocking a Ne...   \n",
       "2           2      SimplyCook Raises £4.5M in Series A Funding\\n   \n",
       "3           3        Moogsoft Secures $40M in Series D Funding\\n   \n",
       "4           4     Zeta Global acquires commenting service†Disqus   \n",
       "\n",
       "                                             content  \\\n",
       "0  Tibit Communications, Inc., a Petaluma, CA-bas...   \n",
       "1  Over the holiday weekend, The New York Times f...   \n",
       "2  SimplyCook, a London, UK-based recipe kit serv...   \n",
       "3  Moogsoft, a San Francisco, CA-based provider o...   \n",
       "4  A source close to the two companies tells us t...   \n",
       "\n",
       "                                                link      source    class  \\\n",
       "0  http://www.finsmes.com/2019/04/tibit-communica...  FinsmesUSA  Funding   \n",
       "1  https://techcrunch.com/2017/11/27/twitter-blam...  techcrunch    Other   \n",
       "2  http://www.finsmes.com/2019/01/simplycook-rais...   FinsmesUK  Funding   \n",
       "3  http://www.finsmes.com/2018/03/moogsoft-secure...  FinsmesUSA  Funding   \n",
       "4  https://techcrunch.com/2017/12/05/zeta-global-...  techcrunch    Other   \n",
       "\n",
       "                                    modified_content  \n",
       "0  organization, a Petaluma, organization-based s...  \n",
       "1  Over the holiday weekend, organization found t...  \n",
       "2  organization, a London, UK-based recipe kit se...  \n",
       "3  organization, a San Francisco, organization-ba...  \n",
       "4  A source close to the two companies tells us t...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset/data/ner_articles_dataset.csv')\n",
    "data = data[~data['content'].isnull()]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>class</th>\n",
       "      <th>modified_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tibit Communications Raises $20M in Series B F...</td>\n",
       "      <td>Tibit Communications, Inc., a Petaluma, CA-bas...</td>\n",
       "      <td>http://www.finsmes.com/2019/04/tibit-communica...</td>\n",
       "      <td>FinsmesUSA</td>\n",
       "      <td>1</td>\n",
       "      <td>organization, a Petaluma, organization-based s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Twitter blames human error after blocking a Ne...</td>\n",
       "      <td>Over the holiday weekend, The New York Times f...</td>\n",
       "      <td>https://techcrunch.com/2017/11/27/twitter-blam...</td>\n",
       "      <td>techcrunch</td>\n",
       "      <td>0</td>\n",
       "      <td>Over the holiday weekend, organization found t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SimplyCook Raises £4.5M in Series A Funding\\n</td>\n",
       "      <td>SimplyCook, a London, UK-based recipe kit serv...</td>\n",
       "      <td>http://www.finsmes.com/2019/01/simplycook-rais...</td>\n",
       "      <td>FinsmesUK</td>\n",
       "      <td>1</td>\n",
       "      <td>organization, a London, UK-based recipe kit se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Moogsoft Secures $40M in Series D Funding\\n</td>\n",
       "      <td>Moogsoft, a San Francisco, CA-based provider o...</td>\n",
       "      <td>http://www.finsmes.com/2018/03/moogsoft-secure...</td>\n",
       "      <td>FinsmesUSA</td>\n",
       "      <td>1</td>\n",
       "      <td>organization, a San Francisco, organization-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Zeta Global acquires commenting service†Disqus</td>\n",
       "      <td>A source close to the two companies tells us t...</td>\n",
       "      <td>https://techcrunch.com/2017/12/05/zeta-global-...</td>\n",
       "      <td>techcrunch</td>\n",
       "      <td>0</td>\n",
       "      <td>A source close to the two companies tells us t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Tibit Communications Raises $20M in Series B F...   \n",
       "1           1  Twitter blames human error after blocking a Ne...   \n",
       "2           2      SimplyCook Raises £4.5M in Series A Funding\\n   \n",
       "3           3        Moogsoft Secures $40M in Series D Funding\\n   \n",
       "4           4     Zeta Global acquires commenting service†Disqus   \n",
       "\n",
       "                                             content  \\\n",
       "0  Tibit Communications, Inc., a Petaluma, CA-bas...   \n",
       "1  Over the holiday weekend, The New York Times f...   \n",
       "2  SimplyCook, a London, UK-based recipe kit serv...   \n",
       "3  Moogsoft, a San Francisco, CA-based provider o...   \n",
       "4  A source close to the two companies tells us t...   \n",
       "\n",
       "                                                link      source  class  \\\n",
       "0  http://www.finsmes.com/2019/04/tibit-communica...  FinsmesUSA      1   \n",
       "1  https://techcrunch.com/2017/11/27/twitter-blam...  techcrunch      0   \n",
       "2  http://www.finsmes.com/2019/01/simplycook-rais...   FinsmesUK      1   \n",
       "3  http://www.finsmes.com/2018/03/moogsoft-secure...  FinsmesUSA      1   \n",
       "4  https://techcrunch.com/2017/12/05/zeta-global-...  techcrunch      0   \n",
       "\n",
       "                                    modified_content  \n",
       "0  organization, a Petaluma, organization-based s...  \n",
       "1  Over the holiday weekend, organization found t...  \n",
       "2  organization, a London, UK-based recipe kit se...  \n",
       "3  organization, a San Francisco, organization-ba...  \n",
       "4  A source close to the two companies tells us t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'] = data['class'].map({'Funding':1, 'Other':0})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>class</th>\n",
       "      <th>modified_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tibit Communications Raises $20M in Series B F...</td>\n",
       "      <td>Tibit Communications, Inc., a Petaluma, CA-bas...</td>\n",
       "      <td>http://www.finsmes.com/2019/04/tibit-communica...</td>\n",
       "      <td>FinsmesUSA</td>\n",
       "      <td>1</td>\n",
       "      <td>organization, a Petaluma, organization-based s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Twitter blames human error after blocking a Ne...</td>\n",
       "      <td>Over the holiday weekend, The New York Times f...</td>\n",
       "      <td>https://techcrunch.com/2017/11/27/twitter-blam...</td>\n",
       "      <td>techcrunch</td>\n",
       "      <td>0</td>\n",
       "      <td>Over the holiday weekend, organization found t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SimplyCook Raises £4.5M in Series A Funding\\n</td>\n",
       "      <td>SimplyCook, a London, UK-based recipe kit serv...</td>\n",
       "      <td>http://www.finsmes.com/2019/01/simplycook-rais...</td>\n",
       "      <td>FinsmesUK</td>\n",
       "      <td>1</td>\n",
       "      <td>organization, a London, UK-based recipe kit se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Moogsoft Secures $40M in Series D Funding\\n</td>\n",
       "      <td>Moogsoft, a San Francisco, CA-based provider o...</td>\n",
       "      <td>http://www.finsmes.com/2018/03/moogsoft-secure...</td>\n",
       "      <td>FinsmesUSA</td>\n",
       "      <td>1</td>\n",
       "      <td>organization, a San Francisco, organization-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Zeta Global acquires commenting service†Disqus</td>\n",
       "      <td>A source close to the two companies tells us t...</td>\n",
       "      <td>https://techcrunch.com/2017/12/05/zeta-global-...</td>\n",
       "      <td>techcrunch</td>\n",
       "      <td>0</td>\n",
       "      <td>A source close to the two companies tells us t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Tibit Communications Raises $20M in Series B F...   \n",
       "1           1  Twitter blames human error after blocking a Ne...   \n",
       "2           2      SimplyCook Raises £4.5M in Series A Funding\\n   \n",
       "3           3        Moogsoft Secures $40M in Series D Funding\\n   \n",
       "4           4     Zeta Global acquires commenting service†Disqus   \n",
       "\n",
       "                                             content  \\\n",
       "0  Tibit Communications, Inc., a Petaluma, CA-bas...   \n",
       "1  Over the holiday weekend, The New York Times f...   \n",
       "2  SimplyCook, a London, UK-based recipe kit serv...   \n",
       "3  Moogsoft, a San Francisco, CA-based provider o...   \n",
       "4  A source close to the two companies tells us t...   \n",
       "\n",
       "                                                link      source  class  \\\n",
       "0  http://www.finsmes.com/2019/04/tibit-communica...  FinsmesUSA      1   \n",
       "1  https://techcrunch.com/2017/11/27/twitter-blam...  techcrunch      0   \n",
       "2  http://www.finsmes.com/2019/01/simplycook-rais...   FinsmesUK      1   \n",
       "3  http://www.finsmes.com/2018/03/moogsoft-secure...  FinsmesUSA      1   \n",
       "4  https://techcrunch.com/2017/12/05/zeta-global-...  techcrunch      0   \n",
       "\n",
       "                                    modified_content  \n",
       "0  organization, a Petaluma, organization-based s...  \n",
       "1  Over the holiday weekend, organization found t...  \n",
       "2  organization, a London, UK-based recipe kit se...  \n",
       "3  organization, a San Francisco, organization-ba...  \n",
       "4  A source close to the two companies tells us t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = round(0.8 * data.shape[0])\n",
    "dev_end = train_size + round(0.1 * data.shape[0])\n",
    "\n",
    "train_df = data.iloc[:train_size, :]\n",
    "dev_df = data.iloc[train_size : dev_end, :]\n",
    "test_df = data.iloc[dev_end :]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0803 21:35:45.479371 139944051242816 deprecation_wrapper.py:119] From /home/brianmusisi/anaconda3/lib/python3.7/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the Lowercase BERT model on Tensorflow hub\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create input examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_examples(df):\n",
    "  examples = df.apply(lambda row : run_classifier.InputExample(guid=None, text_a=row['modified_content'], text_b=None, label= row['class']), axis=1)\n",
    "  return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = create_input_examples(train_df)\n",
    "dev_examples = create_input_examples(dev_df)\n",
    "test_examples = create_input_examples(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting examples to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_features(example, max_len, tokenizer):\n",
    "  \n",
    "  example_tokens = tokenizer.tokenize(example.text_a)\n",
    "  \n",
    "  if len(example_tokens)> max_len -2:\n",
    "    example_tokens = example_tokens[: (max_len -2)]\n",
    "   \n",
    "  tokens = ['[CLS]']\n",
    "  tokens = tokens + example_tokens + ['[SEP]']\n",
    "  tokens=  tokens + ['[PAD]'] * (max_len - len(tokens))\n",
    "  \n",
    "  segment_ids = [0 for token in tokens]\n",
    "  input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "  input_masks = [1] * (len(example_tokens) + 1) + [0] * (max_len - len(example_tokens) -1)\n",
    "  \n",
    "  return input_ids, input_masks, segment_ids, example.label\n",
    "\n",
    "\n",
    "def convert_example_list_to_features(tokenizer, examples, max_len):\n",
    "  input_ids = []\n",
    "  input_masks = []\n",
    "  segment_ids = []\n",
    "  labels = []\n",
    "  \n",
    "  for example in examples:\n",
    "    input_id, input_mask, segment_id, label = convert_example_to_features(example, max_len, tokenizer)\n",
    "    input_ids.append(input_id)\n",
    "    input_masks.append(input_mask)\n",
    "    segment_ids.append(segment_id)\n",
    "    labels.append(label)\n",
    "  \n",
    "  return np.array(input_ids), np.array(input_masks), np.array(segment_ids), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels) = convert_example_list_to_features(tokenizer, train_examples.tolist(), max_len=256)\n",
    "(dev_input_ids, dev_input_masks, dev_segment_ids, dev_labels) = convert_example_list_to_features(tokenizer, dev_examples.tolist(), max_len=256)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels) = convert_example_list_to_features(tokenizer, test_examples.tolist(), max_len=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First create BertLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\",\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        trainable_vars = self.bert.variables\n",
    "        \n",
    "        # Remove unused layers\n",
    "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "        \n",
    "        # Select how many layers to fine tune\n",
    "        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "        \n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "        \n",
    "        # Add non-trainable weights\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        \n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "            \"pooled_output\"\n",
    "        ]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_1 (BertLayer)        (None, 768)          108931396   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          196864      bert_layer_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            257         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,128,517\n",
      "Trainable params: 6,102,273\n",
      "Non-trainable params: 103,026,244\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "in_id = tf.keras.layers.Input(shape=(max_len,), name=\"input_ids\")\n",
    "in_mask = tf.keras.layers.Input(shape=(max_len,), name=\"input_masks\")\n",
    "in_segment = tf.keras.layers.Input(shape=(max_len,), name=\"segment_ids\")\n",
    "bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "# Instantiate the custom Bert Layer defined above\n",
    "bert_output = BertLayer(n_fine_tune_layers=10)(bert_inputs)\n",
    "\n",
    "# Build the rest of the classifier \n",
    "dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start session and initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "def initialize_session(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)\n",
    "    \n",
    "initialize_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35225 samples, validate on 4403 samples\n",
      "Epoch 1/15\n",
      "35225/35225 [==============================] - 274s 8ms/sample - loss: 0.7630 - acc: 0.5339 - val_loss: 0.5712 - val_acc: 0.7231\n",
      "Epoch 2/15\n",
      "35225/35225 [==============================] - 272s 8ms/sample - loss: 0.4007 - acc: 0.8282 - val_loss: 0.3406 - val_acc: 0.8608\n",
      "Epoch 3/15\n",
      "35225/35225 [==============================] - 272s 8ms/sample - loss: 0.2824 - acc: 0.8928 - val_loss: 0.2658 - val_acc: 0.8958\n",
      "Epoch 4/15\n",
      "35225/35225 [==============================] - 272s 8ms/sample - loss: 0.2632 - acc: 0.9027 - val_loss: 0.2470 - val_acc: 0.9005\n",
      "Epoch 5/15\n",
      "35225/35225 [==============================] - 272s 8ms/sample - loss: 0.2470 - acc: 0.9062 - val_loss: 0.2349 - val_acc: 0.9105\n",
      "Epoch 6/15\n",
      "35225/35225 [==============================] - 272s 8ms/sample - loss: 0.2362 - acc: 0.9122 - val_loss: 0.2290 - val_acc: 0.9162\n",
      "Epoch 7/15\n",
      "35225/35225 [==============================] - 272s 8ms/sample - loss: 0.2315 - acc: 0.9135 - val_loss: 0.2327 - val_acc: 0.9107\n",
      "Epoch 8/15\n",
      "35225/35225 [==============================] - 272s 8ms/sample - loss: 0.2236 - acc: 0.9183 - val_loss: 0.2388 - val_acc: 0.9126\n",
      "Epoch 9/15\n",
      "35225/35225 [==============================] - 272s 8ms/sample - loss: 0.2132 - acc: 0.9226 - val_loss: 0.2384 - val_acc: 0.9126\n",
      "Epoch 10/15\n",
      "35225/35225 [==============================] - 272s 8ms/sample - loss: 0.2104 - acc: 0.9228 - val_loss: 0.2298 - val_acc: 0.9112\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "history = model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([dev_input_ids, dev_input_masks, dev_segment_ids], dev_labels),\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4403/4403 [==============================] - 24s 6ms/sample - loss: 0.2537 - acc: 0.9032\n",
      "Testing Accuracy:  0.9032\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([test_input_ids, test_input_masks, test_segment_ids], test_labels)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
